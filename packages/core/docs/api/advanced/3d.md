# 3D Rendering API

OpenTUI provides advanced 3D rendering capabilities through integration with Three.js and WebGPU, allowing you to create rich visual experiences in the terminal.

## Three.js Integration

OpenTUI integrates with Three.js to provide 3D rendering capabilities in the terminal.

### Setting Up Three.js

```typescript
import { createCliRenderer, BoxRenderable } from '@opentui/core';
import * as THREE from 'three';

async function setup3DScene() {
  const renderer = await createCliRenderer();
  const { root } = renderer;
  
  // Create a container for the 3D scene
  const container = new BoxRenderable('container', {
    width: '100%',
    height: '100%',
    border: false
  });
  
  root.add(container);
  
  // Create a Three.js scene
  const scene = new THREE.Scene();
  
  // Create a camera
  const camera = new THREE.PerspectiveCamera(
    75,                                     // Field of view
    renderer.width / renderer.height,       // Aspect ratio
    0.1,                                    // Near clipping plane
    1000                                    // Far clipping plane
  );
  camera.position.z = 5;
  
  // Create a renderer
  const threeRenderer = new THREE.WebGLRenderer({ alpha: true });
  threeRenderer.setSize(renderer.width, renderer.height);
  
  // Create a cube
  const geometry = new THREE.BoxGeometry();
  const material = new THREE.MeshBasicMaterial({ color: 0x00ff00, wireframe: true });
  const cube = new THREE.Mesh(geometry, material);
  scene.add(cube);
  
  // Animation loop
  renderer.setFrameCallback(async (deltaTime) => {
    // Rotate the cube
    cube.rotation.x += 0.01;
    cube.rotation.y += 0.01;
    
    // Render the scene
    threeRenderer.render(scene, camera);
    
    // Get the rendered image data
    const imageData = threeRenderer.domElement.getContext('2d').getImageData(
      0, 0, renderer.width, renderer.height
    );
    
    // Convert the 3D rendering to terminal representation
    for (let y = 0; y < container.height; y++) {
      for (let x = 0; x < container.width; x++) {
        // Sample the WebGL output (with proper scaling)
        const glX = Math.floor(x * (threeRenderer.domElement.width / container.width));
        const glY = Math.floor(y * (threeRenderer.domElement.height / container.height));
        
        const idx = (glY * threeRenderer.domElement.width + glX) * 4;
        const r = imageData.data[idx] / 255;
        const g = imageData.data[idx + 1] / 255;
        const b = imageData.data[idx + 2] / 255;
        const a = imageData.data[idx + 3] / 255;
        
        if (a > 0.1) {
          // Draw the pixel to the terminal buffer
          container.buffer.setCell(
            container.x + x,
            container.y + y,
            ' ',  // Use space character with background color
            RGBA.fromValues(0, 0, 0, 0),  // Transparent foreground
            RGBA.fromValues(r, g, b, a)   // Background color from the 3D scene
          );
        }
      }
    }
  });
  
  // Start the renderer
  renderer.start();
  
  return renderer;
}

// Create and run the 3D scene
setup3DScene().catch(console.error);
```

## WebGPU Integration

OpenTUI provides WebGPU integration for high-performance graphics rendering.

### WGPURenderer

The `WGPURenderer` class provides a WebGPU-based renderer for OpenTUI.

```typescript
import { WGPURenderer } from '@opentui/core/3d';

// Create a WebGPU renderer
const gpuRenderer = new WGPURenderer({
  width: 80,
  height: 40,
  device: null,  // Will be initialized automatically
  format: null   // Will be initialized automatically
});

// Initialize the renderer
await gpuRenderer.initialize();

// Create a render pipeline
const pipeline = await gpuRenderer.createRenderPipeline({
  vertex: {
    module: device.createShaderModule({
      code: vertexShaderCode
    }),
    entryPoint: 'main'
  },
  fragment: {
    module: device.createShaderModule({
      code: fragmentShaderCode
    }),
    entryPoint: 'main',
    targets: [{ format: gpuRenderer.format }]
  },
  primitive: {
    topology: 'triangle-list'
  }
});

// Render a frame
gpuRenderer.beginFrame();
// ... rendering commands ...
gpuRenderer.endFrame();

// Get the rendered image
const imageData = gpuRenderer.getImageData();
```

### Example: WebGPU Shader

```typescript
import { createCliRenderer, BoxRenderable, OptimizedBuffer, RGBA } from '@opentui/core';
import { WGPURenderer } from '@opentui/core/3d';

// Vertex shader
const vertexShaderCode = `
@vertex
fn main(@builtin(vertex_index) VertexIndex : u32) -> @builtin(position) vec4<f32> {
  var pos = array<vec2<f32>, 3>(
    vec2<f32>(0.0, 0.5),
    vec2<f32>(-0.5, -0.5),
    vec2<f32>(0.5, -0.5)
  );
  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);
}
`;

// Fragment shader
const fragmentShaderCode = `
@fragment
fn main() -> @location(0) vec4<f32> {
  return vec4<f32>(1.0, 0.0, 0.0, 1.0);
}
`;

async function createShaderDemo() {
  const renderer = await createCliRenderer();
  const { root } = renderer;
  
  // Create a container
  const container = new BoxRenderable('container', {
    width: '100%',
    height: '100%',
    border: false
  });
  
  root.add(container);
  
  // Create a WebGPU renderer
  const gpuRenderer = new WGPURenderer({
    width: renderer.width * 2,  // Double resolution for better quality
    height: renderer.height * 2
  });
  
  // Initialize the renderer
  await gpuRenderer.initialize();
  
  // Create a render pipeline
  const pipeline = await gpuRenderer.createRenderPipeline({
    vertex: {
      module: gpuRenderer.device.createShaderModule({
        code: vertexShaderCode
      }),
      entryPoint: 'main'
    },
    fragment: {
      module: gpuRenderer.device.createShaderModule({
        code: fragmentShaderCode
      }),
      entryPoint: 'main',
      targets: [{ format: gpuRenderer.format }]
    },
    primitive: {
      topology: 'triangle-list'
    }
  });
  
  // Create a custom renderable for the shader
  class ShaderRenderable extends BoxRenderable {
    private gpuRenderer: WGPURenderer;
    private pipeline: GPURenderPipeline;
    
    constructor(id: string, gpuRenderer: WGPURenderer, pipeline: GPURenderPipeline, options = {}) {
      super(id, {
        width: '100%',
        height: '100%',
        border: false,
        ...options
      });
      
      this.gpuRenderer = gpuRenderer;
      this.pipeline = pipeline;
    }
    
    protected renderSelf(buffer: OptimizedBuffer, deltaTime: number): void {
      // Render with WebGPU
      this.gpuRenderer.beginFrame();
      
      const passEncoder = this.gpuRenderer.commandEncoder.beginRenderPass({
        colorAttachments: [{
          view: this.gpuRenderer.textureView,
          clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
          loadOp: 'clear',
          storeOp: 'store'
        }]
      });
      
      passEncoder.setPipeline(this.pipeline);
      passEncoder.draw(3);  // Draw a triangle
      passEncoder.end();
      
      this.gpuRenderer.endFrame();
      
      // Get the rendered image
      const imageData = this.gpuRenderer.getImageData();
      
      // Convert to terminal representation
      for (let y = 0; y < this.height; y++) {
        for (let x = 0; x < this.width; x++) {
          // Sample the WebGPU output (with proper scaling)
          const gpuX = Math.floor(x * (this.gpuRenderer.width / this.width));
          const gpuY = Math.floor(y * (this.gpuRenderer.height / this.height));
          
          const idx = (gpuY * this.gpuRenderer.width + gpuX) * 4;
          const r = imageData.data[idx] / 255;
          const g = imageData.data[idx + 1] / 255;
          const b = imageData.data[idx + 2] / 255;
          const a = imageData.data[idx + 3] / 255;
          
          if (a > 0.1) {
            // Draw the pixel
            buffer.setCell(
              this.x + x,
              this.y + y,
              ' ',  // Use space character with background color
              RGBA.fromValues(0, 0, 0, 0),
              RGBA.fromValues(r, g, b, a)
            );
          }
        }
      }
    }
  }
  
  // Create the shader renderable
  const shaderView = new ShaderRenderable('shader', gpuRenderer, pipeline);
  container.add(shaderView);
  
  // Start the renderer
  renderer.start();
  
  return renderer;
}

// Create and run the shader demo
createShaderDemo().catch(console.error);
```

## Sprite Rendering

OpenTUI provides sprite rendering capabilities for displaying images in the terminal.

### SpriteResourceManager

The `SpriteResourceManager` class manages sprite resources for efficient rendering.

```typescript
import { SpriteResourceManager } from '@opentui/core/3d';
import Jimp from 'jimp';

// Create a sprite resource manager
const spriteManager = new SpriteResourceManager();

// Load a sprite
const sprite = await spriteManager.loadSprite('path/to/sprite.png');

// Load a sprite from a Jimp image
const jimpImage = await Jimp.read('path/to/another_sprite.png');
const spriteFromJimp = await spriteManager.loadSpriteFromJimp(jimpImage);

// Get a sprite by ID
const cachedSprite = spriteManager.getSprite('sprite_id');

// Release a sprite
spriteManager.releaseSprite('sprite_id');

// Clear all sprites
spriteManager.clear();
```

### Example: Rendering Sprites

```typescript
import { createCliRenderer, BoxRenderable, OptimizedBuffer, RGBA } from '@opentui/core';
import { SpriteResourceManager } from '@opentui/core/3d';

async function createSpriteDemo() {
  const renderer = await createCliRenderer();
  const { root } = renderer;
  
  // Create a container
  const container = new BoxRenderable('container', {
    width: '100%',
    height: '100%',
    border: false,
    backgroundColor: '#222222'
  });
  
  root.add(container);
  
  // Create a sprite resource manager
  const spriteManager = new SpriteResourceManager();
  
  // Load sprites
  const characterSprite = await spriteManager.loadSprite('path/to/character.png');
  const backgroundSprite = await spriteManager.loadSprite('path/to/background.png');
  
  // Create a custom renderable for sprites
  class SpriteRenderable extends BoxRenderable {
    private sprite: any;
    private scale: number;
    
    constructor(id: string, sprite: any, options = {}) {
      super(id, {
        width: sprite.width,
        height: sprite.height / 2,  // Terminal characters are roughly 2:1 ratio
        border: false,
        position: 'absolute',
        ...options
      });
      
      this.sprite = sprite;
      this.scale = options.scale || 1;
    }
    
    protected renderSelf(buffer: OptimizedBuffer): void {
      // Render the sprite
      for (let y = 0; y < this.height; y++) {
        for (let x = 0; x < this.width; x++) {
          // Sample the sprite pixel
          const spriteX = Math.floor(x / this.scale);
          const spriteY = Math.floor(y / this.scale * 2);  // Adjust for terminal aspect ratio
          
          if (spriteX < this.sprite.width && spriteY < this.sprite.height) {
            // Get pixel color from the sprite
            const idx = (spriteY * this.sprite.width + spriteX) * 4;
            const r = this.sprite.data[idx] / 255;
            const g = this.sprite.data[idx + 1] / 255;
            const b = this.sprite.data[idx + 2] / 255;
            const a = this.sprite.data[idx + 3] / 255;
            
            if (a > 0.5) {
              // Draw the pixel
              buffer.setCell(
                this.x + x,
                this.y + y,
                ' ',
                RGBA.fromValues(0, 0, 0, 0),
                RGBA.fromValues(r, g, b, a)
              );
            }
          }
        }
      }
    }
  }
  
  // Create background sprite
  const background = new SpriteRenderable('background', backgroundSprite, {
    x: 0,
    y: 0,
    width: renderer.width,
    height: renderer.height,
    scale: backgroundSprite.width / renderer.width
  });
  
  // Create character sprite
  const character = new SpriteRenderable('character', characterSprite, {
    x: 20,
    y: 15,
    scale: 0.5
  });
  
  // Add sprites to the container
  container.add(background);
  container.add(character);
  
  // Add keyboard controls for the character
  renderer.on('key', (data) => {
    const key = data.toString();
    
    switch (key) {
      case 'w':
        character.y = Math.max(0, character.y - 1);
        break;
      case 's':
        character.y = Math.min(renderer.height - character.height, character.y + 1);
        break;
      case 'a':
        character.x = Math.max(0, character.x - 1);
        break;
      case 'd':
        character.x = Math.min(renderer.width - character.width, character.x + 1);
        break;
    }
  });
  
  // Start the renderer
  renderer.start();
  
  return renderer;
}

// Create and run the sprite demo
createSpriteDemo().catch(console.error);
```

## Texture Loading

OpenTUI provides utilities for loading and managing textures.

### TextureUtils

The `TextureUtils` class provides utilities for working with textures.

```typescript
import { TextureUtils } from '@opentui/core/3d';
import Jimp from 'jimp';

// Load a texture
const texture = await TextureUtils.loadTexture('path/to/texture.png');

// Load a texture from a Jimp image
const jimpImage = await Jimp.read('path/to/another_texture.png');
const textureFromJimp = TextureUtils.textureFromJimp(jimpImage);

// Create a texture from raw data
const rawData = new Uint8Array([/* RGBA pixel data */]);
const rawTexture = TextureUtils.createTexture(rawData, 32, 32);

// Resize a texture
const resizedTexture = TextureUtils.resizeTexture(texture, 64, 64);

// Crop a texture
const croppedTexture = TextureUtils.cropTexture(texture, 10, 10, 20, 20);

// Get a pixel from a texture
const pixel = TextureUtils.getPixel(texture, 5, 5);
console.log(`RGBA: ${pixel.r}, ${pixel.g}, ${pixel.b}, ${pixel.a}`);
```

## Lighting and Materials

When using Three.js integration, you can create advanced lighting and materials.

### Example: Phong Lighting

```typescript
import { createCliRenderer, BoxRenderable } from '@opentui/core';
import * as THREE from 'three';

async function createLightingDemo() {
  const renderer = await createCliRenderer();
  const { root } = renderer;
  
  // Create a container
  const container = new BoxRenderable('container', {
    width: '100%',
    height: '100%',
    border: false
  });
  
  root.add(container);
  
  // Create a Three.js scene
  const scene = new THREE.Scene();
  
  // Create a camera
  const camera = new THREE.PerspectiveCamera(
    75,
    renderer.width / renderer.height,
    0.1,
    1000
  );
  camera.position.z = 5;
  
  // Create a renderer
  const threeRenderer = new THREE.WebGLRenderer({ alpha: true });
  threeRenderer.setSize(renderer.width * 2, renderer.height * 2);
  
  // Create a cube with Phong material
  const geometry = new THREE.BoxGeometry();
  const material = new THREE.MeshPhongMaterial({
    color: 0x3498db,
    specular: 0xffffff,
    shininess: 30
  });
  const cube = new THREE.Mesh(geometry, material);
  scene.add(cube);
  
  // Add lighting
  const ambientLight = new THREE.AmbientLight(0x404040);
  scene.add(ambientLight);
  
  const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
  directionalLight.position.set(1, 1, 1);
  scene.add(directionalLight);
  
  const pointLight = new THREE.PointLight(0xff0000, 1, 100);
  pointLight.position.set(2, 2, 2);
  scene.add(pointLight);
  
  // Animation loop
  renderer.setFrameCallback(async (deltaTime) => {
    // Rotate the cube
    cube.rotation.x += 0.01;
    cube.rotation.y += 0.01;
    
    // Move the point light in a circle
    const time = Date.now() * 0.001;
    pointLight.position.x = Math.sin(time) * 3;
    pointLight.position.z = Math.cos(time) * 3;
    
    // Render the scene
    threeRenderer.render(scene, camera);
    
    // Get the rendered image data
    const imageData = threeRenderer.domElement.getContext('2d').getImageData(
      0, 0, threeRenderer.domElement.width, threeRenderer.domElement.height
    );
    
    // Convert the 3D rendering to terminal representation
    for (let y = 0; y < container.height; y++) {
      for (let x = 0; x < container.width; x++) {
        // Sample the WebGL output with proper scaling
        const glX = Math.floor(x * (threeRenderer.domElement.width / container.width));
        const glY = Math.floor(y * (threeRenderer.domElement.height / container.height));
        
        const idx = (glY * threeRenderer.domElement.width + glX) * 4;
        const r = imageData.data[idx] / 255;
        const g = imageData.data[idx + 1] / 255;
        const b = imageData.data[idx + 2] / 255;
        const a = imageData.data[idx + 3] / 255;
        
        // Apply lighting effects to enhance visibility in terminal
        const brightness = Math.max(r, g, b);
        const character = brightness > 0.8 ? '█' : 
                         brightness > 0.6 ? '▓' : 
                         brightness > 0.4 ? '▒' : 
                         brightness > 0.2 ? '░' : ' ';
        
        // Draw the pixel with appropriate character and color
        buffer.setCell(
          container.x + x,
          container.y + y,
          character,
          RGBA.fromValues(r, g, b, a),
          RGBA.fromValues(0, 0, 0, 1)
        );
      }
    }
  });
  
  // Start the renderer
  renderer.start();
  
  return renderer;
}

// Create and run the lighting demo
createLightingDemo().catch(console.error);
```

## Shaders

OpenTUI supports custom shaders for advanced visual effects.

### Example: Fractal Shader

```typescript
import { createCliRenderer, BoxRenderable, OptimizedBuffer, RGBA } from '@opentui/core';
import { WGPURenderer } from '@opentui/core/3d';

// Vertex shader
const vertexShaderCode = `
@vertex
fn main(@builtin(vertex_index) VertexIndex : u32) -> @builtin(position) vec4<f32> {
  var pos = array<vec2<f32>, 6>(
    vec2<f32>(-1.0, -1.0),
    vec2<f32>(1.0, -1.0),
    vec2<f32>(1.0, 1.0),
    vec2<f32>(-1.0, -1.0),
    vec2<f32>(1.0, 1.0),
    vec2<f32>(-1.0, 1.0)
  );
  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);
}
`;

// Fragment shader (Mandelbrot fractal)
const fragmentShaderCode = `
@group(0) @binding(0) var<uniform> time: f32;

@fragment
fn main(@builtin(position) fragCoord: vec4<f32>) -> @location(0) vec4<f32> {
  let resolution = vec2<f32>(80.0, 40.0);
  let uv = (fragCoord.xy / resolution) * 2.0 - 1.0;
  uv.x *= resolution.x / resolution.y;
  
  // Mandelbrot parameters
  let zoom = 0.8 + 0.2 * sin(time * 0.1);
  let centerX = -0.5 + 0.1 * sin(time * 0.05);
  let centerY = 0.0 + 0.1 * cos(time * 0.05);
  
  // Map to Mandelbrot space
  let c = vec2<f32>(uv.x / zoom + centerX, uv.y / zoom + centerY);
  let z = vec2<f32>(0.0, 0.0);
  
  // Mandelbrot iteration
  let maxIter = 100;
  var iter = 0;
  for (var i = 0; i < maxIter; i++) {
    // z = z^2 + c
    let x = z.x * z.x - z.y * z.y + c.x;
    let y = 2.0 * z.x * z.y + c.y;
    z = vec2<f32>(x, y);
    
    if (dot(z, z) > 4.0) {
      iter = i;
      break;
    }
  }
  
  // Coloring
  if (iter == maxIter) {
    return vec4<f32>(0.0, 0.0, 0.0, 1.0);
  } else {
    let t = f32(iter) / f32(maxIter);
    let r = 0.5 + 0.5 * sin(t * 6.28 + time);
    let g = 0.5 + 0.5 * sin(t * 6.28 + time + 2.09);
    let b = 0.5 + 0.5 * sin(t * 6.28 + time + 4.18);
    return vec4<f32>(r, g, b, 1.0);
  }
}
`;

async function createFractalShaderDemo() {
  const renderer = await createCliRenderer();
  const { root } = renderer;
  
  // Create a container
  const container = new BoxRenderable('container', {
    width: '100%',
    height: '100%',
    border: false
  });
  
  root.add(container);
  
  // Create a WebGPU renderer
  const gpuRenderer = new WGPURenderer({
    width: renderer.width,
    height: renderer.height
  });
  
  // Initialize the renderer
  await gpuRenderer.initialize();
  
  // Create a uniform buffer for time
  const uniformBuffer = gpuRenderer.device.createBuffer({
    size: 4,  // 4 bytes for a float
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
  });
  
  // Create a bind group layout
  const bindGroupLayout = gpuRenderer.device.createBindGroupLayout({
    entries: [{
      binding: 0,
      visibility: GPUShaderStage.FRAGMENT,
      buffer: { type: 'uniform' }
    }]
  });
  
  // Create a bind group
  const bindGroup = gpuRenderer.device.createBindGroup({
    layout: bindGroupLayout,
    entries: [{
      binding: 0,
      resource: { buffer: uniformBuffer }
    }]
  });
  
  // Create a pipeline layout
  const pipelineLayout = gpuRenderer.device.createPipelineLayout({
    bindGroupLayouts: [bindGroupLayout]
  });
  
  // Create a render pipeline
  const pipeline = await gpuRenderer.device.createRenderPipeline({
    layout: pipelineLayout,
    vertex: {
      module: gpuRenderer.device.createShaderModule({
        code: vertexShaderCode
      }),
      entryPoint: 'main'
    },
    fragment: {
      module: gpuRenderer.device.createShaderModule({
        code: fragmentShaderCode
      }),
      entryPoint: 'main',
      targets: [{ format: gpuRenderer.format }]
    },
    primitive: {
      topology: 'triangle-list'
    }
  });
  
  // Create a custom renderable for the shader
  class FractalShaderRenderable extends BoxRenderable {
    private gpuRenderer: WGPURenderer;
    private pipeline: GPURenderPipeline;
    private bindGroup: GPUBindGroup;
    private uniformBuffer: GPUBuffer;
    private startTime: number;
    
    constructor(id: string, gpuRenderer: WGPURenderer, pipeline: GPURenderPipeline, 
                bindGroup: GPUBindGroup, uniformBuffer: GPUBuffer, options = {}) {
      super(id, {
        width: '100%',
        height: '100%',
        border: false,
        ...options
      });
      
      this.gpuRenderer = gpuRenderer;
      this.pipeline = pipeline;
      this.bindGroup = bindGroup;
      this.uniformBuffer = uniformBuffer;
      this.startTime = Date.now();
    }
    
    protected renderSelf(buffer: OptimizedBuffer, deltaTime: number): void {
      // Update time uniform
      const time = (Date.now() - this.startTime) / 1000;
      this.gpuRenderer.device.queue.writeBuffer(this.uniformBuffer, 0, new Float32Array([time]));
      
      // Render with WebGPU
      this.gpuRenderer.beginFrame();
      
      const passEncoder = this.gpuRenderer.commandEncoder.beginRenderPass({
        colorAttachments: [{
          view: this.gpuRenderer.textureView,
          clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
          loadOp: 'clear',
          storeOp: 'store'
        }]
      });
      
      passEncoder.setPipeline(this.pipeline);
      passEncoder.setBindGroup(0, this.bindGroup);
      passEncoder.draw(6);  // Draw two triangles (a quad)
      passEncoder.end();
      
      this.gpuRenderer.endFrame();
      
      // Get the rendered image
      const imageData = this.gpuRenderer.getImageData();
      
      // Convert to terminal representation
      for (let y = 0; y < this.height; y++) {
        for (let x = 0; x < this.width; x++) {
          // Sample the WebGPU output
          const idx = (y * this.gpuRenderer.width + x) * 4;
          const r = imageData.data[idx] / 255;
          const g = imageData.data[idx + 1] / 255;
          const b = imageData.data[idx + 2] / 255;
          const a = imageData.data[idx + 3] / 255;
          
          // Draw the pixel
          buffer.setCell(
            this.x + x,
            this.y + y,
            ' ',  // Use space character with background color
            RGBA.fromValues(0, 0, 0, 0),
            RGBA.fromValues(r, g, b, a)
          );
        }
      }
    }
  }
  
  // Create the fractal shader renderable
  const fractalView = new FractalShaderRenderable(
    'fractal',
    gpuRenderer,
    pipeline,
    bindGroup,
    uniformBuffer
  );
  container.add(fractalView);
  
  // Start the renderer
  renderer.start();
  
  return renderer;
}

// Create and run the fractal shader demo
createFractalShaderDemo().catch(console.error);
```
